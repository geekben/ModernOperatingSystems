##1.3 计算机硬件概览
操作系统与其运行的硬件环境是紧密相关的。它延伸了计算机的指令集并且为计算机管理各种资源。要让计算机正常工作，操作系统必须非常了解硬件，至少要对这些硬件暴露给程序员的接口了如指掌。因此，让我们简要的浏览一下当今计算机系统通常使用的硬件设备。有了这些知识，我们就能开始详细了解操作系统和其运行原理。

一个简单的个人计算机可以被抽象为图1-6那样的模型。CPU，内存和IO设备都连接在一条系统总线上，并通过这条总线相互通信。现代操作系统具有更加复杂的结构，有多种总线，我们后面会谈到。暂时来说，这种模型就足够分析问题了。后面的章节中，我们将简要概述上述各个组成部件，并且深入剖析一些操作系统设计者们关系的硬件问题。不用说，这将是个非常简洁的综述。关于计算机硬件和计算机组成的书有很多。两本最著名的是 Tanenbaum and Austin (2012) 和 Patterson and Hennessy (2013)。

###1.3.1 处理器
计算机的大脑是CPU，它从内存中取指令并执行。CPU最简单的工作流程就是，从内存读取第一条指令，解码以确定其类型和操作数，执行它，然后读取，解码，执行后续的指令。这种流程被一直重复，直到程序结束。程序就是这样被运行的。

每种CPU都有其独有的指令集。因此，x86处理器不能执行ARM的程序，反之亦然。因为访问内存读取指令和数据的时间比执行指令的时间长很多，所以所有CPU都拥有一些寄存器，用于存放关键变量和临时结果。因此，指令集都包含了从内存加载数据到寄存器和保存寄存器数据到内存的指令。其他一些指令，将两个操作数组合为一个结果，这两个操作数可以来自内存也可以来自寄存器，或者各取一个；比如就有指令将两个操作数做加法，结果存入寄存器或者内存中。

除了上述用于存放数据的通用寄存器，大多处理器含有一些程序员可见的特殊寄存器。其中之一是**程序计数器**，它包含了下一条要读取的指令的内存地址。处理器读取了一条指令后，程序计数器将被更新，指向下一条指令。

另一个寄存器是**栈指针**，它指向内存中栈的顶端。栈保存了每个已经开始但尚未结束的程序流程的数据帧。这种数据帧包含了入参，局部变量和没有使用寄存器保存的临时变量。

再一个寄存器是**PSW**（程序状态字）。这个寄存器包含了数个条件码bits(*N(negative)Z(zero)V(overflow)C(carry)*)，它们由比较指令来设置，还包含了CPU优先级寄存器，运行模式（用户态或内核态），还有一些其他控制位。用户态程序通常可以读取整个PSW，但是只能写其中一些位。PSW寄存器在系统调用和IO中扮演了重要角色(*x86的EFlags包含了上面的条件码bits*)。

操作系统必须完全感知这些寄存器。对CPU进行分时复用时，操作系统会经常停止正在运行的程序去启动或者重启另外一个程序。每次它停止一个程序的时候，必须把这些寄存器都保存下来，这样，当这个程序再次运行时就可以恢复他们。

为了提高性能，操作系统的设计者早就放弃了对单一指令读取解析执行这一流程。许多现代CPU都有同时并行执行多条指令的能力。比如，某种CPU可能具有分离的读取，解析，执行单元。于是，当它在执行第n条指令时，可能同时在解析第n+1条指令，并同时在读取第n+2条指令。这种组织方式，被称作流水线，图1-7（a）描述了三阶段的流水线结构。实际上流水线通常更长。大多数流水线设计中，一条指令被读取后，它必须被执行。即使之前的指令是条件转移指令。流水线让编译器和操作系统的作者无比头痛，因为他们将不得不直面底层系统的复杂性。

比流水线设计更复杂的是超标量处理器，如图1-7（b）所示。这种设计中，安排了多个执行单元，比如可以同时拥有一个整型运算器，一个浮点型运算器，一个布尔运算器。一次读取2条或者更多的指令，解析后存放在一个缓冲区中，等待执行。一旦有执行单位空闲出来，立即检查缓冲区，看看有没有自己可以执行的指令在其中，如果有则将这条指令从缓冲区中移除并执行。这种设计带来的一个影响是，指令常常会乱序执行。大部分情况下，由硬件来保证程序乱序执行和顺序执行的结果保持一致，但是还是给操作系统强加了一些恼人的复杂性，后面我们会谈到。

除了一些在嵌入式系统中使用的简单CPU，大部分的CPU都有用户态和内核态两种运行模式。一般由PSW寄存器中的一个bit来控制当前运行模式。当处于内核态时，CPU可以执行指令集里的所有指令，并使用所有硬件特性。在桌面电脑或者服务器上，操作系统一般都运行在内核态，可以访问整个硬件。在大多数嵌入式系统中，只有一小段代码运行在内核态，剩余的操作系统代码都运行在用户态。（*这一句是否说反了，嵌入式系统的用户态程序很少，剩下都是操作系统才对吧*）

用户程序通常运行在用户态，只被允许执行指令集的一个子集，只能访问部分硬件特性。大体上说，牵涉到IO和内存保护的指令都不能在用户态执行。比如，设置PSW寄存器中的运行模式位，让CPU进入内核态，理所当然是被禁止了的。

用户程序必须通过系统调用来获取操作系统提供的服务。系统调用会使程序陷入内核并触发操作系统工作。TRAP指令将系统从用户态切换到内核态并启动操作系统。当操作系统完成请求的任务，它就将控制权交换给用户程序，从刚刚完成的系统调用的下一条指令开始执行。我们将在后面讨论系统调用机制的细节。我们暂时就把系统调用当作一种特殊的程序调用过程，只不过具有从内核态到用户态切换的附加功能而已。
在此说明一下，我们后面会用小写的斜体字代表系统调用名称：*read*。

除了系统调用，其他的指令引起的陷入没有太大的价值。大部分的其他陷入都是硬件对异常情况的告警。比如除零异常和浮点数向下溢出异常。所有的这些情况，操作系统都会得到控制权，从而决定该如何应对。有时，程序必须被终止并返回错误码，有时候则完全可以忽略这些异常（向下溢出的数值可以直接设置为0）。最后，如果程序事先声明了它自己需要对异常情况做一些处理，那么操作系统会把控制权交还给程序，让他们自己有机会处理这些问题。

####多线程和多核芯片
摩尔定律声称，芯片上的集成电路密度每隔18个月翻一番。这个定律并不是某种类似动量守恒那样的物理定律，只不过是摩尔根据自己对半导体公司中那些工艺流程工程师们将二极管体积缩小的速度的观察得出的规律总结。摩尔定律在过去30年中都一直被坚守，而且预计还将在未来十年或者更长时间保持有效性。在这之后，每个二极管上的原子个数将少到足以令量子力学开始产生巨大影响，让继续缩小二极管体积成为不可能。

二极管数量的极大丰富带来了一个问题：我们怎么发挥所有二极管的能力？我们看到了一种方式：具有多种功能单元的超标量架构。但是，二极管数量仍然在增加，可用的越来越多。一件显而易见的事情就是增加CPU上的缓存数，而大家确实就是这么做的，但最终收益拐点还是会来临。

容易想到的下一步就是不仅仅复制多个功能单元，同时也在一个处理器核上复制多份控制逻辑。Intel奔腾4处理器引入了这项技术，被称作多线程或者超线程技术（Intel独有的名称）。不仅在x86处理器上，其他CPU芯片也具备这种新技术，包括SPARC，Power5，英特尔至强，英特尔Core系列。简单来说，这项技术所做的就是在一个CPU上同时保持两个线程上下文，在他们之间不断的进行纳秒级的切换。（线程就是轻量级的进程，而进程就是一个在执行中的程序，这个我们会在第二章里面介绍）举个例子，如果一个进程需要从内存里面读取一个数据（这会消耗很多个CPU周期），此时多线程的CPU可以切换到另一个线程去执行。多线程处理器并没有提供真正的并行性，某一时刻只有一个线程真正在运行，但是线程切换的时间却被缩小到了纳秒级。

多线程技术对操作系统也产生了影响，因为每个线程对操作系统来说就是个独立的CPU。想象一个系统拥有两个CPU，而每一个又有两个超线程，那么将认为系统拥有4个CPU。如果系统负载仅能保持两个CPU处于工作状态，那么操作系统很可能不经意的将这两个线程调度到同一个CPU的两个超线程上，而另一片CPU将完全空闲。这种调度选择显然没有只在CPU使用其中一个线程效率高。

除了超线程，许多CPU芯片都有4个8个甚至更多的完整的核。如图1-8所示的多核处理器实际上包含了4个迷你芯片，每片都是独立的CPU。（缓存将在下面解释）有些处理器，比如英特尔Xeon Phi和Tilera的TilePro，已经将60多个核心放在一个CPU芯片上。使用这样的多核处理器，必须要有个支持多处理器的操作系统。

顺提一句，要比绝对数量，谁也不是现今GPU（graphics processing unit）的对手。GPU是一个可以具有几千个微核心的处理器。他们非常擅长对大量小型计算任务的并行处理，比如在图像处理应用中对边形的渲染。但是他们对串行任务则显得力不从心。同时，编写GPU程序也是很困难的。虽然GPU对操作系统很有用（处理加密或处理网络通信任务），但是操作系统自身却几乎不可能跑在GPU上。
